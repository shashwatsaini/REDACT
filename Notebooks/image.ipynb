{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document contains content:  Shashwat Saini +919970013662 | shashwatsaini290@gmail.com | LinkedIn | GitHub\n",
      "EDUCATION\n",
      "Dayananda Sagar University B.Tech. in Computer Science Engineering- Artificial Intelligence & Machine Learning\n",
      "Bengaluru, Karnataka 2022 - 2026 Chennai, Tamil Nadu 2023 - 2027\n",
      "Indian Institute of Technology Madras B.S. in Data Science & Applications\n",
      "EXPERIENCE\n",
      "Machine Learning Intern\n",
      "July 2024 - August 2024 Bengaluru, Karnataka\n",
      "AIMonk Labs Private Ltd.\n",
      "· Designed and evaluated multi-agent systems using Microsoft Autogen, Crew.AI, OpenAI, and LangChain.\n",
      "· Developed an advanced content re-purposing system to summarize videos, generate highlights and reels, as well as Twitter tweets, and Instagram posts.\n",
      "· Deployed the system on a remote server with MongoDB, incorporating result caching and a front-end for testing.\n",
      "RESEARCH PUBLICATIONS\n",
      "Saini, S., Vrindavanam, J., & Mondal, S. (2024). Methodological Insights into Protein Clustering Using BERT And ROBERTa. IEEE CONECCT 2024, Indian Institute of Science.\n",
      "This paper presents the usage of BERT and ROBERTa models to classify 25,000 protein sequences into their respective functions by pre-training on masked amino acids and fine-tuning with respect to their Gene Ontology annotations.\n",
      "Saini, S. & Mondal, S. (2024). GEM-X: Gene Expression Modelling Using XLNet and Other Transformer Architectures. Health and Technology. Submitted.\n",
      "This paper introduces XLNet and other transformer architectures for gene expression modeling from RNA-Seq data of over 500 patients, classifying them as cancerous or healthy. It details preprocessing for class imbalance, analysis of model principles, and a training mechanism achieving 99% accuracy.\n",
      "PROJECTS\n",
      "ACCORD: An AI-powered App for Sponsors & Influencers | Flask, Autogen, Google Gemini, SQL, Javascript\n",
      "· Developed ACCORD, a platform for Sponsors & Influencers to collaborate, centered around a Multi-Agent Recommendation System with Autogen & Google Gemini.\n",
      "· Built a secure backend using Flask, SQLAlchemy, and Flask Login, ensuring robust user management.\n",
      "· Fine-tuned Google Gemini to be a Helper Bot for real-time assistance and efficient campaign management.\n",
      "· Implemented AI-driven features like Profile & Campaign Insights, enabling users to collaborate and engage easily.\n",
      "Extracting Topographical Features Using A U-NET | Tensorflow, OpenCV\n",
      "· Developed an automated system to extract topographical features from geographical data from the DeepGlobe Challenge. The system deciphers road networks from satellite images using binary masks.\n",
      "· Employed a U-NET architecture with a VGG19 model as the encoder and Convolutional Layers as the decoder.\n",
      "· With over 11.5 million tunable parameters, results showcase an accuracy of 98% and a precision of 97%.\n",
      "GRCh38 Protein Clustering | Biopython, Pytorch, cuDF, cuDNN\n",
      "· Developed a k-means model to cluster 2000 proteins from the GRCh38 human genome.\n",
      "· Feature engineering to compute amino acid composition with structural data, preserving spatial relationships.\n",
      "· Trained and tested multiple models on UniProt (a protein database) and translated proteins from the genome.\n",
      "CERTIFICATES\n",
      "Tensorflow Developer Specialization, Deeplearning.AI Natural Language Processing Specialization, Deeplearning.AI\n",
      "January 2024 November 2023\n",
      "TECHNICAL SKILLS\n",
      "Frameworks: Tensorflow, PyTorch, Autogen, Crew.AI, LangChain, Hugging Face, OpenAI, Google Gemini, Google Mediapipe, Scikit Learn Developer Tools: Git, Docker, Google Cloud Platform, AWS EC2, VS Code, PyCharm Libraries: CuDF, CuPY, Pandas, Numpy\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "endpoint = \"\"\n",
    "key = \"\"\n",
    "\n",
    "image_path = \"example.png\" # Enter image path here\n",
    "\n",
    "def format_bounding_box(bounding_box):\n",
    "    if not bounding_box:\n",
    "        return \"N/A\"\n",
    "    return \", \".join([\"[{}, {}]\".format(p.x, p.y) for p in bounding_box])\n",
    "\n",
    "def analyze_read():\n",
    "    # Sample document\n",
    "    form_path = image_path\n",
    "\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "    \n",
    "    with open(form_path, \"rb\") as form_file:\n",
    "        poller = document_analysis_client.begin_analyze_document(\n",
    "            model_id=\"prebuilt-read\", document=form_file\n",
    "        )\n",
    "        result = poller.result()\n",
    "\n",
    "    print(\"Document contains content: \", result.content)\n",
    "\n",
    "    for page in result.pages:\n",
    "        for line_idx, line in enumerate(page.lines):\n",
    "            continue\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = analyze_read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = {\n",
    "    'model': 'llama3.1',\n",
    "    'base_url': 'http://localhost:11434/v1',\n",
    "    'api_key': 'ollama',\n",
    "}\n",
    "\n",
    "chat_outline = {\n",
    "    'message': result.content\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_assistant = autogen.ConversableAgent(\n",
    "    'assistant', \n",
    "    system_message='OBJECTIVE: You are an agent designed to identify personal information from any text provided to you.\\n'\n",
    "                   'Your sole task is to output a Python list of words or phrases that need to be redacted based on the following categories:'\n",
    "                   '[Names, Proper Nouns, Company Names, Full Dates, Phone Numbers, Email Addresses, Physical Addresses, Social Security Numbers].\\n'\n",
    "                   'IMPORTANT: Your output MUST strictly be a SINGLE Python list of strings representing the items that need to be redacted.'\n",
    "                   'Example Output: [\"John Doe\", \"123-456-7890\"].\\n'\n",
    "                   'You should NOT respond with explanations, code blocks, or any other format.\\n'\n",
    "                   'DO NOT explain or comment on your reasoning; just output the list.\\n'\n",
    "                   'FAILURE EXAMPLE (do not output this): \"The following need to be redacted...\"\\n'\n",
    "                   'SUCCESS EXAMPLE (the correct output): [\"John Doe\", \"123-456-7890\"].',\n",
    "    llm_config=config_list, \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "evaluation = autogen.ConversableAgent(\n",
    "    'evaluation-agent',\n",
    "    system_message='OBJECTIVE: You are an evaluation agent responsible for reviewing text to ensure that all personal information has been correctly redacted.\\n'\n",
    "                   'Your task is to verify whether any personal information from the following LIST has been missed:'\n",
    "                   ' [Names, Proper Nouns, Company Names, Full Dates, Months, Phone Numbers, Email Addresses, Physical Addresses, Country Names, Social Security Numbers].\\n'\n",
    "                   'If any of this information is still present, flag the specific issue and provide feedback on the missing redactions.\\n'\n",
    "                   'OUTPUT: Provide your feedback as bullet points, listing any additional word(s) or phrases that need to be redacted.\\n'\n",
    "                   'Example Output: \\n'\n",
    "                   '- \"John Doe\" (Name)\\n'\n",
    "                   '- \"123-456-7890\" (Phone Number)\\n'\n",
    "                   'Do not provide explanations or reasoning, only the missing redactions in this format.',\n",
    "    llm_config=config_list,\n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    'user_proxy', \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_state = 1\n",
    "speakers = []\n",
    "def text_redact_selection_func(speaker: autogen.AssistantAgent, groupchat: autogen.GroupChat):\n",
    "    global conversation_state\n",
    "    if speaker == user_proxy and conversation_state == 1:\n",
    "        conversation_state += 1\n",
    "        speakers.append(text_assistant.name)\n",
    "        return text_assistant\n",
    "    elif speaker == text_assistant and conversation_state == 2:\n",
    "        conversation_state += 1\n",
    "        speakers.append(evaluation.name)\n",
    "        return evaluation\n",
    "    elif speaker == evaluation and conversation_state == 3:\n",
    "        conversation_state += 1\n",
    "        speakers.append(text_assistant.name)\n",
    "        return text_assistant\n",
    "\n",
    "text_redaction_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy, text_assistant, evaluation],\n",
    "    speaker_selection_method=text_redact_selection_func,\n",
    "    messages=[],\n",
    "    max_round=4\n",
    ")\n",
    "\n",
    "text_redaction_manager = autogen.GroupChatManager(\n",
    "    groupchat=text_redaction_chat, llm_config=config_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Shashwat Saini +919970013662 | shashwatsaini290@gmail.com | LinkedIn | GitHub\n",
      "EDUCATION\n",
      "Dayananda Sagar University B.Tech. in Computer Science Engineering- Artificial Intelligence & Machine Learning\n",
      "Bengaluru, Karnataka 2022 - 2026 Chennai, Tamil Nadu 2023 - 2027\n",
      "Indian Institute of Technology Madras B.S. in Data Science & Applications\n",
      "EXPERIENCE\n",
      "Machine Learning Intern\n",
      "July 2024 - August 2024 Bengaluru, Karnataka\n",
      "AIMonk Labs Private Ltd.\n",
      "· Designed and evaluated multi-agent systems using Microsoft Autogen, Crew.AI, OpenAI, and LangChain.\n",
      "· Developed an advanced content re-purposing system to summarize videos, generate highlights and reels, as well as Twitter tweets, and Instagram posts.\n",
      "· Deployed the system on a remote server with MongoDB, incorporating result caching and a front-end for testing.\n",
      "RESEARCH PUBLICATIONS\n",
      "Saini, S., Vrindavanam, J., & Mondal, S. (2024). Methodological Insights into Protein Clustering Using BERT And ROBERTa. IEEE CONECCT 2024, Indian Institute of Science.\n",
      "This paper presents the usage of BERT and ROBERTa models to classify 25,000 protein sequences into their respective functions by pre-training on masked amino acids and fine-tuning with respect to their Gene Ontology annotations.\n",
      "Saini, S. & Mondal, S. (2024). GEM-X: Gene Expression Modelling Using XLNet and Other Transformer Architectures. Health and Technology. Submitted.\n",
      "This paper introduces XLNet and other transformer architectures for gene expression modeling from RNA-Seq data of over 500 patients, classifying them as cancerous or healthy. It details preprocessing for class imbalance, analysis of model principles, and a training mechanism achieving 99% accuracy.\n",
      "PROJECTS\n",
      "ACCORD: An AI-powered App for Sponsors & Influencers | Flask, Autogen, Google Gemini, SQL, Javascript\n",
      "· Developed ACCORD, a platform for Sponsors & Influencers to collaborate, centered around a Multi-Agent Recommendation System with Autogen & Google Gemini.\n",
      "· Built a secure backend using Flask, SQLAlchemy, and Flask Login, ensuring robust user management.\n",
      "· Fine-tuned Google Gemini to be a Helper Bot for real-time assistance and efficient campaign management.\n",
      "· Implemented AI-driven features like Profile & Campaign Insights, enabling users to collaborate and engage easily.\n",
      "Extracting Topographical Features Using A U-NET | Tensorflow, OpenCV\n",
      "· Developed an automated system to extract topographical features from geographical data from the DeepGlobe Challenge. The system deciphers road networks from satellite images using binary masks.\n",
      "· Employed a U-NET architecture with a VGG19 model as the encoder and Convolutional Layers as the decoder.\n",
      "· With over 11.5 million tunable parameters, results showcase an accuracy of 98% and a precision of 97%.\n",
      "GRCh38 Protein Clustering | Biopython, Pytorch, cuDF, cuDNN\n",
      "· Developed a k-means model to cluster 2000 proteins from the GRCh38 human genome.\n",
      "· Feature engineering to compute amino acid composition with structural data, preserving spatial relationships.\n",
      "· Trained and tested multiple models on UniProt (a protein database) and translated proteins from the genome.\n",
      "CERTIFICATES\n",
      "Tensorflow Developer Specialization, Deeplearning.AI Natural Language Processing Specialization, Deeplearning.AI\n",
      "January 2024 November 2023\n",
      "TECHNICAL SKILLS\n",
      "Frameworks: Tensorflow, PyTorch, Autogen, Crew.AI, LangChain, Hugging Face, OpenAI, Google Gemini, Google Mediapipe, Scikit Learn Developer Tools: Git, Docker, Google Cloud Platform, AWS EC2, VS Code, PyCharm Libraries: CuDF, CuPY, Pandas, Numpy\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "[\"Shashwat Saini\", \"+919970013662\", \"shashwatsaini290@gmail.com\", \"LinkedIn\", \"GitHub\", \"Dayananda Sagar University\", \"Indian Institute of Technology Madras\", \"AIMonk Labs Private Ltd.\", \"IEEE CONECCT 2024\", \"Indian Institute of Science\", \"Health and Technology\", \"ACCORD\"]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: evaluation-agent\n",
      "\u001b[0m\n",
      "\u001b[33mevaluation-agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Here is the list of missing redactions:\n",
      "\n",
      "* \"Shashwat Saini\" (Name)\n",
      "* \"+919970013662\" (Phone Number)\n",
      "* \"shashwatsaini290@gmail.com\" (Email Address)\n",
      "* \"LinkedIn\" (Social Media Profile)\n",
      "* \"GitHub\" (Social Media Profile)\n",
      "* \"Dayananda Sagar University\" (Company Name/Education Institution)\n",
      "* \"Indian Institute of Technology Madras\" (Company Name/Education Institution)\n",
      "* \"AIMonk Labs Private Ltd.\" (Company Name)\n",
      "* \"+919970013662\" (Phone Number in text with international prefix)\n",
      "* July 2024 - August 2024 (Full Date Interval)\n",
      "* B.Tech. in Computer Science Engineering- Artificial Intelligence & Machine Learning (Education Programme)\n",
      "* Bengaluru, Karnataka (Physical Address)\n",
      "* Chennai, Tamil Nadu (Physical Address)\n",
      "* January 2024 November 2023 (Full Date Interval)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "[\"Shashwat Saini\", \"+919970013662\", \"shashwatsaini290@gmail.com\", \"LinkedIn\", \"GitHub\", \"Dayananda Sagar University\", \"Indian Institute of Technology Madras\", \"AIMonk Labs Private Ltd.\", \"+919970013662\", \"July 2024 - August 2024\", \"B.Tech. in Computer Science Engineering- Artificial Intelligence & Machine Learning\", \"Bengaluru, Karnataka\", \"Chennai, Tamil Nadu\", \"January 2024 November 2023\"]\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text_redaction_chats = user_proxy.initiate_chat(\n",
    "    text_redaction_manager,\n",
    "    message=chat_outline['message']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shashwat',\n",
       " 'Saini',\n",
       " '+919970013662',\n",
       " 'shashwatsaini290@gmail.com',\n",
       " 'LinkedIn',\n",
       " 'GitHub',\n",
       " 'Dayananda',\n",
       " 'Sagar',\n",
       " 'University',\n",
       " 'Indian',\n",
       " 'Institute',\n",
       " 'Technology',\n",
       " 'Madras',\n",
       " 'AIMonk',\n",
       " 'Labs',\n",
       " 'Private',\n",
       " 'Ltd.',\n",
       " '+919970013662',\n",
       " 'July',\n",
       " '2024',\n",
       " 'August',\n",
       " '2024',\n",
       " 'B.Tech.',\n",
       " 'Computer',\n",
       " 'Science',\n",
       " 'Engineering-',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'Bengaluru,',\n",
       " 'Karnataka',\n",
       " 'Chennai,',\n",
       " 'Tamil',\n",
       " 'Nadu',\n",
       " 'January',\n",
       " '2024',\n",
       " 'November',\n",
       " '2023']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "redacted_text = text_redaction_chats.chat_history[-1]['content']\n",
    "redacted_text = ast.literal_eval(redacted_text)\n",
    "redacted_words = []\n",
    "for text in redacted_text:\n",
    "    for word in str(text).split(' '):\n",
    "        if len(word) > 3:\n",
    "            redacted_words.append(word)\n",
    "redacted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(598.0, 96.0), (914.0, 96.0), (914.0, 155.0), (598.0, 153.0)],\n",
       " [(941.0, 96.0), (1104.0, 95.0), (1105.0, 154.0), (941.0, 155.0)],\n",
       " [(443.0, 161.0), (629.0, 160.0), (630.0, 190.0), (444.0, 190.0)],\n",
       " [(652.0, 160.0), (998.0, 160.0), (998.0, 190.0), (653.0, 190.0)],\n",
       " [(1033.0, 160.0), (1139.0, 160.0), (1139.0, 190.0), (1033.0, 190.0)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redacted_cords = []\n",
    "for page in result.pages:\n",
    "        for word in page.words:\n",
    "                if word.content in redacted_words:\n",
    "                    cords = []\n",
    "                    for polygon in word.polygon:\n",
    "                           cords.append((polygon.x, polygon.y))\n",
    "                    redacted_cords.append(cords)\n",
    "redacted_cords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Load the original image\n",
    "image_path = image_path\n",
    "image = Image.open(image_path)\n",
    "draw = ImageDraw.Draw(image)\n",
    "width, height = image.size\n",
    "\n",
    "# For each set of coordinates, draw the black boxes\n",
    "for coord_set in redacted_cords:\n",
    "    x_coords = [point[0] for point in coord_set]\n",
    "    y_coords = [point[1] for point in coord_set]\n",
    "    x_min, x_max = min(x_coords), max(x_coords)\n",
    "    y_min, y_max = min(y_coords), max(y_coords)\n",
    "    draw.rectangle([x_min, y_min, x_max, y_max], fill='black')\n",
    "\n",
    "image.save('modified_image.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
